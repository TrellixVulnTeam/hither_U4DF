4/18 updates

---

For now, I have removed that messy code that tried to check whether the same job was simultaneously queued multiple times. It was buggy and needs to be redone.

---

I am trying to simplify the process of auto-transferring files to/from the compute resource via kachery. Here is how it is working now:

download_results is a hither configuration parameter for jobs. If set to True, then the results of the job will always be downloaded to the client by way of kachery.

By default download_results is set to False, so that we do not transfer data when it is not needed. In that case we need to auto-detect when the results are actually needed on the client.

Let's consider the following example:

```python
with hi.Config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)
    b = a.wait()
```

In this case, the wait() command is requesting that the file created on the compute resource be downloaded to the client. However, at the time that the job was created, this requirement was not known. This case is pretty easy to handle. Since the job has not yet been sent to the compute resource by the time that wait() is called, we can simply retrospectively (internally) set the `job._download_results=True` and it's not too late. That should be handled in the code right now, but not yet tested.

The following example is more difficult:

```python
with hi.Config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)
    hi.wait()
    b = a.wait()
```

In this case, the `hi.wait()` command blocks the execution, and we don't know that we need `a` locally until the `a.wait()` call. This case is not yet handled in the code.

Note: internally we will implement something like:

```python
with hi.Config(job_handler=remote_job_handler, download_results=True):
    a = hi.identity.run(x=a)
```

Now consider the following slightly more complex example:

```python
with hi.Config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)

with hi.Config(job_handler=local_job_handler):
    b = do_something_locally_with_large_file.run(x=a)
```

Here, the second `run()` is called before the first job is sent to the compute resource. Therefore, `a._download_results=True` can simply be set on the job `a` retrospectively. I think this is already implemented, but not yet tested.

Now consider the more difficult situation:

```python
with hi.Config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)
    hi.wait()

with hi.Config(job_handler=local_job_handler):
    b = do_something_locally_with_large_file.run(x=a)
```

This is very similar to the above situation, and can be handled in the same way.

```python
with hi.Config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)
    a = a.wait(resolve=False)

with hi.Config(job_handler=local_job_handler):
    b = do_something_locally_with_large_file.run(x=a['some-file'])
```

At the time that `do_something_locally_with_large_file.run()` is called, the system needs to somehow retrieve the result file `a['some-file']` from the compute resource. To facilitate this, a `_remote_job_handler` attribute is attached to the files in `a`. So every file generated by a remote compute resource will have this attribute attached to it. Then the second call will be replaced (internally) by the following:

```python
with hi.Config(job_handler=local_job_handler):
    with hi.Config(job_handler=a['some_file']._remote_job_handler, download_results=True):
        f = hi.identity(x=a['some_file'])
    b = do_something_locally_with_large_file.run(x=f)
```

Here, `identity` is an internal hither function that simply returns whatever is sent to it. Note that it gets executed on the remote compute resource (where the file lives) and the `download_results` is set to True, so it will be downloaded to the client computer prior to `do_something_locally_with_large_file` being called.
