4/18 updates

---

For now, I have removed that messy code that tried to check whether the same job was simultaneously queued multiple times. It was buggy and needs to be redone.

---

I am trying to simplify the process of auto-transferring files to/from the compute resource via kachery. Here is how it is working now:

download_results is a hither2 configuration parameter for jobs. If set to True, then the results of the job will always be downloaded to the client by way of kachery.

By default download_results is set to False, so that we do not transfer data when it is not needed. In that case we need to auto-detect when the results are actually needed on the client.

Let's consider the following example:

```python
with hi.config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)
    b = a.wait()
```

In this case, the wait() command is requesting that the file created on the compute resource be downloaded to the client. However, at the time that the job was created, this was not known. This case is pretty easy to handle. Since the job has not yet been sent to the compute resource by the time that wait() is called, we can simply retrospectively (internally) set the job._download_results=True and it's not too late. That should be handled in the code right now, but not yet tested.

The following example is more difficult:

```python
with hi.config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)
    hi.wait()
    b = a.wait()
```

In this case, the hi.wait() command blocks the execution, and we don't know that we need a locally until the a.wait() call. This case is not yet handled in the code.

Now consider the following slightly more complex example:

```python
with hi.config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)

with hi.config(job_handler=local_job_handler):
    b = do_something_locally_with_large_file.run(x=a)
```

Here, the second `run()` is called before the first job is sent to the compute resource. Therefore, `_download_results=True` can simply be set on the job `a` retrospectively. The code should do this, but not yet tested.

Now consider the more difficult situation:

```python
with hi.config(job_handler=remote_job_handler):
    a = create_some_large_file.run(size=1e9)
    hi.wait()

with hi.config(job_handler=local_job_handler):
    b = do_something_locally_with_large_file.run(x=a['some_file'])
```

At the time that `do_something_locally_with_large_file.run()` is called, the system needs to somehow retrieve the result files in `a` from the compute resource. To facilitate this, a `_remote_job_handler` attribute is attached to the files in `a`. So every file generated by a remote compute resource will have this attribute attached to it. Then the second call will be replaced (internally) by the following:

```python
with hi.config(job_handler=local_job_handler):
    with hi.config(job_handler=a['some_file']._remote_job_handler, download_results=True):
        f = identity(a['some_file'])
    b = do_something_locally_with_large_file.run(x=f)
```

Here, `identity` is an internal hither2 function that simply returns whatever is sent to it. Note that it gets executed on the remote compute resource (where the file lives) and the `download_results` is set to True, so it will be downloaded to the client computer prior to `do_something_locally_with_large_file` being called.
